# ğŸ§  Enterprise RAG Chatbot Microservice (LangChain + FAISS + FastAPI)

This project is a production-style Retrieval-Augmented Generation (RAG) microservice using:
- **LangChain** for chaining retrieval + generation
- **FAISS** as the vector database
- **OpenAI** for embedding + language model
- **FastAPI** for serving queries via API

Built and structured like a microservice that can scale to enterprise usage.

---

## âœ… Features

- ğŸ—‚ï¸ Document ingestion and chunking
- ğŸ” Vector search over embedded content (FAISS)
- ğŸ¤– GPT-3.5-Turbo-based RAG response
- ğŸ§¾ Source citation in answers
- âš™ï¸ API-first architecture via FastAPI
- ğŸ“ Local PDF upload and embedding endpoint
- ğŸ“Š Evaluation logging for every query

---

## ğŸ“Œ Tech Stack

| Layer         | Tool/Library         |
|---------------|----------------------|
| LLM           | OpenAI GPT-3.5       |
| Embeddings    | OpenAI ADA v2        |
| Retrieval     | FAISS (local vector DB) |
| API Framework | FastAPI              |
| Infra         | Python 3.10+, Uvicorn |

---

## ğŸ” Workflow Diagram

```text
User Query âœ FastAPI âœ Retrieve top-k chunks from FAISS âœ Inject into Prompt âœ OpenAI LLM âœ Final Answer âœ API Response with Sources

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   PDF Upload  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Chunk + Embed â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                           â†“                       â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
User Query â”€â”€â”€â”€â”€â”€â–º â”‚   FAISS DB   â”‚ â”€â”€ Top-K Match â”‚
                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â†“
                         â†“                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     Inject in Prompt â”€â”€â–º â”‚ GPT (OpenAI)   â”‚
                                          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                â†“
                                          Final Answer
```

---

## ğŸ“¥ API Endpoints

### ğŸ”¹ 1. `/ask` â€“ Ask a Question
```http
POST /ask
Content-Type: application/json

{
  "query": "What is retrieval-augmented generation?"
}
```
**Returns:**
```json
{
  "answer": "...",
  "sources": [{ "source": "page: 3", "file": "data_science_guide.pdf" }]
}
```

---

### ğŸ”¹ 2. `/upload` â€“ Upload and Embed New PDFs
```http
POST /upload
Content-Type: multipart/form-data

form-data:
  file: <your_pdf_file.pdf>
```
ğŸ“ Automatically:
- Saves to `data/docs/`
- Loads, chunks, embeds
- Appends to FAISS index

---

## ğŸ“Š Evaluation Techniques

### 1. **Retrieval Logging**
- Logs `top_k` documents retrieved per query
- Metadata includes page number, source file

### 2. **Answer Traceability**
- Answer includes source document metadata
- Helps verify hallucinations and grounding

### 3. **Fallback Detection**
- If no relevant chunks, returns fallback answer or low-confidence message

### 4. **Manual Feedback Endpoint** (to be added)
```http
POST /feedback
{
  "query": "...",
  "answer": "...",
  "correct": true,
  "comment": "Accurate but incomplete"
}
```
Logs to `feedback.csv` or DB.

---

## ğŸ§  Suggestions for Enterprise-Readiness

| Need                          | How to Add                         |
|-------------------------------|------------------------------------|
| ğŸ” Auth for Upload/Query      | Add JWT + API Key auth             |
| ğŸ“ˆ Monitoring / Logs          | Integrate with Prometheus + Grafana|
| â±ï¸ Rate Limiting              | Use FastAPI middleware             |
| ğŸ§  LLM Evaluation             | Add BLEU, ROUGE metrics on answers |
| ğŸ—ƒï¸ Streaming Support          | Enable OpenAI stream=True          |
| ğŸ§ª Testing / CI               | Add pytest + GitHub Actions        |
| ğŸ³ Deployment                 | Add Docker + Docker Compose        |

---

## ğŸ”§ TODOs for Next Iteration
- [ ] Switch to `LlamaIndex` for modularity + hybrid search
- [ ] Host LLM using SageMaker endpoint
- [ ] Add persistent database (Postgres) for logging queries
- [ ] Support long-context documents (use chunk re-ranking)

---

## ğŸ™Œ Credits
Built with ğŸ’¡ by [@ekta-shukla] â€” for GenAI microservices that scale.

